---
title: "A mixture of hidden Markov models to predict the lymphatic spread in head and neck cancer depending on primary tumor location"
abstract: |
  Purpose: to be done

  Methods: to be done

  Results: to be done

  Conclusions: to be done
---

# Introduction

Head and neck squamous cell carcinomas (HNSCCs) are known to spread through the lymphatic system often leading to metastases in the lymph nodes [@mukherji_cervical_2001;@shah_patterns_1990]. To minimize nodal recurrences, lymph node levels (LNLs) at risk of harboring occult metastases are typically irradiated electively. Current guidelines for different tumor locations are based on the overall prevalence of nodal disease as reported in literature [@biau_selection_2019;@mukherji_cervical_2001;@shah_patterns_1990].

To personalize the prediction of the risk of occult metastases, given a patient's individual diagnosis, we previously published a large, multi-centric dataset where the lymphatic involvement per LNL is available for each patient[@ludwig_dataset_2022;@ludwig_multi-centric_2023]. Building on this dataset, we introduced an interpretable hidden Markov model (HMM), trained to predict the risk for occult nodal disease, given an individual patient's diagnosis [@ludwig_hidden_2021].

Personalized risk predictions could enable clinicians to safely reduce the elective clinical target volume (CTV-N), potentially decreasing treatment-related side effects that impair a patient's quality of life, without compromising the efficacy of the treatment [@batth_practical_2014].

Initially, separate models were trained for distinct tumor locations, such as the oropharynx and oral cavity. These tumor locations are also used in guidelines to define the elective target volumes [@biau_selection_2019]. However, this approach did not account for variations in lymphatic spread between subsites within these tumor regions. With data from more than 2700 patients available, we can now further analyze subsite specific spread patterns. Closer analysis showed that pooling subsites into a single model led to inaccurate predictions, as it failed to capture distinct lymphatic spread patterns. To resolve this, we propose using a mixture of HMMs, which allows us to model the lymphatic spread more accurately for tumors located near anatomical borders, such as those between the oropharynx and oral cavity (e.g., tumors in the palate).

Additionally, we extend the analysis to a broader mixture model that encompasses tumors of the oral cavity, oropharynx, hypopharynx, and larynx, resulting in further personalized predictions of lymphatic spread across these regions.

# Data on Lymphatic Progression Patterns {#sec-data}

For the analyses in this work, we used seven datasets from 5 institutions resulting in {{< var patients.total >}} patients in total.

1. {{< var patients.USZ_oropharynx >}} oropharyngeal patients from the University of Zurich in Switzerland
2. {{< var patients.CLB_oropharynx >}} oropharyngeal patients from the Centre Léon Bérard in France
3. {{< var patients.ISB_multiside >}} oropharyngeal, larynx and oral cavity patients from the Inselspital Bern in Switzerland
4. {{< var patients.CLB_multiside >}} oropharyngeal, larynx and oral cavity patients from the Centre Léon Bérard in France
5. {{< var patients.USZ_multiside >}} oropharyngeal, larynx and oral cavity patients from the University of Zurich in Switzerland
6. {{< var patients.HVH >}} oropharyngeal patients from the Hospital Vall d'Hebron in Spain (not yet public)
7. {{< var patients.HMC >}} hypopharynx, larynx and oral cavity patients from University Medical Center Groningen (not yet public)

Patients with glottic laryngeal cancer (C32.0) at tumor stages T0 and T1 have been excluded from analysis because these stages, by definition, do not exhibit lymphatic involvement [need source from Panos]. The datasets 1-4 are publicly available as CSV tables [@ludwig_multi-centric_2023;@ludwig_detailed_2022] and can be interactively explored on [LyProX](https://lyprox.org). For each patient the primary tumor subsite is reportd and each indicidual LNL is reported as either metastatic or healthy given the available diagnostic modalities, which include pathology after neck dissection in some patients.
In this work we will stratify the tumor locations into different ICD codes which are depicted in @fig-subsites.

![Anatomical sketch of the tumor subsites and their corresponding ICD-10 codes. Subsite C06 "other parts of mouth" has not been included. Further the The tumor locations are color coded in the following pattern: blue-oral cavity, green-oropharynx, red-hypopharynx, orange-larynx.](figures/Subsites.png){#fig-subsites}

The prevelance of involvement in LNLs I, II, III, IV and V is shown in @fig-involvement. The involvement is stratified per tumor subsite and t-stage. The figure illustrates the variations in LNL involvement between subsites within oral cavity (blue), oropharynx (green), hypopharynx (red) and larynx (orange). The involvement pattern presents a continuous change over the tumor subsites. Where tumors in the oral cavity show the most prominent LNL I involvement. As the tumor location moves towards the oropharynx LNL II involvement increases. Moving the tumor location further in caudal direction towards the hypopharynx increases LNL III involvement while LNL I and II involvement decrease. Larnygeal tumors show the least LNL I involvement.

![Prevalence of ipsilateral LNL involvement stratified by subsite. The subsites are sorted in natural order to represent the continuously changing LNL involvement. The different tumo locations are color coded, where oral cavity subsistes are depicted in blue, larynx in green, hypopharynx in red and larynx in orange. The patient data is further stratified in early t-stage (0-2) and late t-stage (3-4). The legend furter specifies the number of patients in each subsite. For glottis (C32.0) early t-stage only includes T2.](figures/involvement_I_to_V_all_sites_t_staging.png){#fig-involvement}

# Unilateral Model for Lymphatic Progression {#sec-unilateral}

In this chapter we will briefly summarize unilateral model for ipsilateral lymph node involvement introduced in @ludwig_hidden_2021, presenting the notation which is then needed to extend the HMM to a mixture model encompassing multiple tumor subsites.

The HMM describes each LNL $v \in 1, 2, ..., V$ by a binary random variable corresponding to the status of the LNL; healthy (0) or involved (1). The entire state of a patient with $V$ LNLs is defined by the $V$-dimensional vector $\mathbf{X} = [X_1, X_2, ...,X_V]$. In the HMM, a patient's involvement is modeled over time $t$. Thus, a patient's state of lymph node involvement $\mathbf{X}[t]$ evolves over discrete time steps $t$. Let us enumerate all $2^V$ possible states, representing all combinations of LNL involvement. In this paper, we consider ipsilateral LNLs I, II, III, IV and V, which amounts to 32 possible states. The HMM is then specified by a transition matrix $\mathbf{A}$:

$$
\mathbf{A} = \begin{pmatrix} A_{ij} \end{pmatrix} = P \left( \mathbf{X}[t+1] = \boldsymbol{\xi}_j \mid \mathbf{X}[t] = \boldsymbol{\xi}_i \right)
$$ {#eq-transition-matrix}

whose elements $A_{ij}$ contain the conditional probabilities that a state $\mathbf{X}[t]=\boldsymbol{\xi}_i$ transitions to $\mathbf{X}[t+1]=\boldsymbol{\xi}_j$ over one time step. The transition matrix is specified and parameterised via the graphical model shown in @fig-graph. The red arcs in the graph of @fig-graph are associated with the probability that the primary tumor spreads directly to a LNL (parameters $b_v$). The blue arcs describe the spread from an upstream LNL -- given it is already metastatic -- to a downstream level (parameters $t_{v \rightarrow v+1}$).

![Parametrized graphical model of the lymphatic network considering four LNLs. Blue nodes represent the hidden states of LNLs $X_v$, while the red one is the tumor. Arcs represent possible routes of metastatic spread, associated with a probability.](figures/Model_5_LNL.png){#fig-graph width=20%}

Now, let $\boldsymbol{\pi}$ be the _starting distribution_

$$
\boldsymbol{\pi} = \begin{pmatrix} \pi_i \end{pmatrix} = P \left( \mathbf{X}[0] = \boldsymbol{\xi}_i \right)
$$ {#eq-starting-distribution}

denoting the probability to start in state $\boldsymbol{\xi}_i$ at time step 0. Assuming that every patient started with all LNLs being healthy, we set $\pi_i$ to zero for all states  except the completly healthy state $\boldsymbol{\xi} = \begin{pmatrix} 0, 0, 0, 0, 0 \end{pmatrix}$, which has probability one.

Using the quantities introduced so far, the probability $P \left( \mathbf{X}[t]=\boldsymbol{\xi}_i \right)$ to be in state $\boldsymbol{\xi}_i$ in time step $t$ can now be conveniently expressed as a matrix product:

$$
P \left( \mathbf{X}[t]=\boldsymbol{\xi}_i \right) = \left( \boldsymbol{\pi} \cdot \mathbf{A}^t \right)_i
$$ {#eq-evolution}

This evolution implicitly marginalizes over all possible paths to arrive at state $\boldsymbol{\xi}_i$ after $t$ time-steps. Additionally, we must marginalize over the unknown time of diagnosis using a time-prior $P_T(t)$ which is defined by a binomial distribution. The t-stage of the tumor can be included in the model by choosing different parameterizations of the binomial distribution, considering that a tumor in late t-stages was diagnosed later than a tumor in early t-stages, therefore shifting the probability of diagnosis to later time steps. This finally defines the probability distribution over all states of lymph node involvement.

$$
P \left( \mathbf{X}=\boldsymbol{\xi}_i \mid \boldsymbol{\theta}, \mathbf{T} \right) = \sum_{t=0}^{t_\text{max}} P_T(t) \left( \boldsymbol{\pi} \cdot \mathbf{A}^t \right)_i
$$ {#eq-marginalized-evolution}

where $\boldsymbol{\theta}=\{ b_v, t_{v \rightarrow v+1} \}$ denotes the set of all model parameters (7 in our case). Fortunately, the exact length and shape of this distribution has little impact as previously shown [@ludwig_hidden_2021]. We set $t_\text{max}=$ {{< var model.max_t >}} and $P_\text{early}(t)$ to a binomial distribution with parameter {{< var model.first_binom_prob >}}. Further details on the HMM can be found in @ludwig_hidden_2021 and @zora231470.

With @eq-marginalized-evolution we can compute the probability of a patient being in any state $\xi_i$. Therefore the likelihood of observing a the
For model training we assume that the diagnoses in our data $\mathbf{D}$ we observe correspond to the hidden state $\mathbf{X}$ of the patient. Thus, learning the model parameters corresponds to maximizing the probability of observing the dataset $\mathbf{D}$:

$$
P \left( \mathbf{D} \mid \boldsymbol{\theta} \right) = \prod_k^K P \left( \mathbf{X}_k=\boldsymbol{\xi}_i \mid \boldsymbol{\theta}, T_k \right)
$$ {#eq-likelihood-HMM}

In @eq-likelihood-HMM we compute the likelihood of observing patient the diagnosis of each patient $k$, i.e. t-stage $T_k$ and involvement  $\mathbf{X}_k=\boldsymbol{\xi}_i$.

# Mixture Model for Lymphatic Spread {#sec-mixture}

Primary tumors at different subsites exhibit distinct lymphatic spread patterns. This presents a challenge when attempting to generalize predictive models across subsites. One approach, as introduced in [@ludwig_dynamic_2021], uses a Hidden Markov Model (HMM) trained specifically for oropharyngeal cancer. However, extending this model to other subsites would either require generalizing over several subsites or training a separate model for each. The former approach sacrifices precision, particularly for subsites with fewer patients, while the latter approach becomes computationally intensive and introduces large uncertainties for subsites with limited patient data, such as C04 (Floor of mouth) or C05 (Palate).

To address these challenges and exploit the anatomical similarities between nearby subsites, we introduce a mixture model that combines data from all subsites into a single model. This model accounts for anatomical proximities, thereby improving predictive power while maintaining computational efficiency.

## Mixture Model Formulation

The mixture model assumes that the data is generated by a set of $M$ different lymphatic spread models. Each patient $k$, with their primary tumor in subsite $s \in (1, 2, \ldots, S)$, is assumed to be generated by one specific model $m \in (1, 2, \ldots, M)$ from this set of $M$ models with probability $\pi_m^s$. These so-called _mixing parameters_ $\boldsymbol{\pi}^s = \{\pi_1^s, \pi_2^s, \dots, \pi_M^s\}$ must satisfy the condition

$$
\sum_{m}^M \pi_m^s = 1, \quad \forall s
$$

If we could record the componet $m$ from which a patient $k$ was drawn from, we could store this information in a binary latent vector $\boldsymbol{\epsilon}_k$. The vector $\boldsymbol{\epsilon}_k$ has length $M$, with exactly the $m$-th element set to 1, indicating which model generated the patient’s data, and all other elements set to 0. Thus, for patient $k$, the latent variable $\boldsymbol{\epsilon}_k$ can be interpreted as a categorical indicator variable that encodes the assignment to one of the $M$ lymphatic spread models. Typically in mixture models, this so-called _latent variable_ is unknown. However, it can be inferred and is useful for inferring the models' parameters.

The joint probability of the observed data $\mathbf{D}$ (i.e., patient data) and the latent variables $\boldsymbol{\epsilon}$ - sometimes called the _complete data likelihood_ - is given by:

$$
P(\mathbf{D}, \boldsymbol{\epsilon} \mid \boldsymbol{\theta}, \boldsymbol{\pi}) = \prod_{k}^{K} \prod_{m}^{M} \left[ \pi_m^{s_k} P(\mathbf{D}_k \mid \boldsymbol{\theta}_m) \right]^{\epsilon_{k}^m}
$$ {#eq-complete-likelihood}

Here:

- $\pi_m^{s_k}$ is the mixing coefficient for subsite $s_k$ (where patient $k$ has their tumor) and model $m$,
- $P(\mathbf{D}_k \mid \boldsymbol{\theta}_m)$ is the likelihood of patient $k$'s diagnosis, i.e. The involvement state $\mathbf{X}_k = \boldsymbol{\xi}_i$ and t-stage $T_k$, given that it was generated by model $m$,
- $\boldsymbol{\theta}_m$ represents the parameters of model $m$,
- $\epsilon_{k}^m$ is the latent variable that indicates patient $k$ was generated by model $m$.

::: {.callout-note}

## TODO: Discuss if we need this
<!-- Not sure we can skip it. We want to maximize this w.r.t. the model parameters. -->

In contrast, the _incomplete data likelihood_ marginalizes over all possible latent assignments to reflect the uncertainty about which model generated each patient’s data:

$$
P(\mathbf{D}, \mid \boldsymbol{\theta}, \boldsymbol{\pi}) = \prod_{k}^{K} \sum_{m}^{M} \pi_m^{s_k} P(\mathbf{D}_k \mid \boldsymbol{\theta}_m)
$$ {#eq-incomplete-likelihood}

Ultimately, we want to find the parameters which maximize this likelihood function for the given data.

Note the summation inside the product. This structure of mixture models makes naive inference difficult, because the logarithm of this quantity is expensive to compute and not easy to differentiate. Thus, inferring the latent assignment is helpful, because the complete data (log-)likelihood (@eq-complete-likelihood) does not suffer from this shortcoming.

:::

To infer the latent assignment $\boldsymbol{\epsilon}_k$, we start with its distribution, given the observed data and model parameters:

$$
\gamma(\epsilon_k^m) := \mathbb{E}[\epsilon_k^m] = \frac{\pi_m^{s_k} P \left( \mathbf{D}_k \mid \boldsymbol{\theta}_m \right)}{\sum_{j \leq M} \pi_j^{s_k} P \left( \mathbf{D}_k \mid \boldsymbol{\theta}_j \right)}
$$ {#eq-responsibilities}

This expectation value - often called the _responsibility_ - describes the probability that patient $k$ was generated by model $m$. It can be used to compute the expected complete data likelihood:

$$
\mathbb{E}_{\boldsymbol{\epsilon}} \left[ P \left( \mathbf{D}, \boldsymbol{\epsilon} \mid \boldsymbol{\theta}, \boldsymbol{\pi} \right) \right] = \prod_{k=1}^K \prod_{m=1}^M \left[ \pi_m^{s_k} P \left( \mathbf{D}_k \mid \boldsymbol{\theta}_m \right) \right]^{\gamma(\epsilon_k^m)}
$$ {#eq-expected-complete-likelihood}

This expected complete data likelihood has the same tractable form as @eq-complete-likelihood and thus allows us to infer both the mixing coefficients $\boldsymbol{\pi}$ as well as each component model's parameters $\boldsymbol{\theta}_m$ using straightformward inference. Also, these two sets of parameters are the only ones used for the later risk prediction. The responsiblities $\gamma(\epsilon_k^m)$ are only used during inference.

In @fig-model-simple the mixture coefficients are illustrated. Subsites with different spread patterns, such as Gum (C03) and Base of tongue (C01), are expected to get different model assignments. Nonetheless, the latent variables for two patients with the same diagnosis, i.e. same involvement $\boldsymbol{\xi}$ and and t-stage $T$, but different subsites are the same.

![Illustration of mixture parameter assignment. Since Gum and Base of tongue express different spread patterns, the two models are expected to have different model assignments. The arrow visibility represents the value of the mixture parameter $\pi$, where the more visible the arrow, the larger the value for $\pi$](figures/mixture_model_simplified.png){#fig-model-simple}

## Expectation-Maximization (EM) Algorithm

To actually find the mixing coefficients $\boldsymbol{\pi}$ and all models' parameters $\boldsymbol{\theta}_m$ that maximize @eq-incomplete-likelihood, we follow an iterative approach called _expectation-maximization_ or _EM-algorithm_. With arbitrarily initialized starting parameters, we alternate between the following two steps:

1. In the **E**xpectation step, we compute the responsibilities $\gamma(\epsilon_k^m)$, which represent the probabilities of a patient $k$ originating from one of the models $m$, given the current estimates of $\boldsymbol{\theta}$ and $\boldsymbol{\pi}$, as given in @eq-responsibilities.
2. During the **M**maximization step, we find a new set of parameters that maximize the new expected complete data likelihood (@eq-expected-complete-likelihood). For the mixture coefficients, we can even find an analytic solution to the new maximum:
   $$
   \pi_m^s = \frac{1}{|K_s|} \sum_{k \in K_s} \gamma(\epsilon_k^m)
   $$
   where we sum over the set of all patients $K_s$ with their tumor in subsite $s$.\
   The models' new parameters are found by numerically maximizing the respective likelihood, weighted by the responsibilities:
   $$
   \ln P(\mathbf{D}, \boldsymbol{\epsilon} \mid \boldsymbol{\theta}_m) = \sum_k^K \gamma(\epsilon^m_{k}) \big[ \ln \pi_m^{s_k} + \ln P \left( \mathbf{D}_k \mid \boldsymbol{\theta}_m \right) \big]
   $$ {#eq-maximization-step}

By iterating these steps, the EM algorithm is guaranteed to converge to a (local) maximum of the complete data likelihood (@eq-complete-likelihood).


# Three component Mixture Model {#sec-3comp}

We illustrate the methodology for a mixture model with M = 3 components, considering the ipsilateral involvement of LNLs I, II, III, IV, and V. We include the ICD codes as subsites for oral cavity, hypopharynx and oropharynx. In @fig-convergence the convergence of the negative log-likelihood and change in model parameters is depicted. After a random inizialization, the algorithm rapidly converges. The algorithm was stopped when the difference of log-likelihood between two iterations was below 0.01.

![The y-axis on the left shows the negative likelihood convergence depicted in the blue line. The y-axis on the right shows the sum of absulte difference between all model parameters showing that the parameter values stabilize rapidly as well.](figures/Convergence_3_comp.png){#fig-convergence}

In @fig-3_simplex, we visualize the resulting mixture coefficients $\boldsymbol{\pi}$ using a spatial representation, where the vertices of the triangle correspond to the three components. In @fig-3-matrix, these mixture coefficients are presented in matrix form, with the y-axis representing the ICD codes, showing how the mixture components in each row add up to 1.

The spatial plot in @fig-3_simplex illustrates how the model assigns the three components to different tumor subsites. Component 0, located at the bottom right of the triangle, primarily characterizes oropharyngeal subsites. For instance, the base of tongue subsite (C01), which exhibits the highest involvement of LNL II, is fully assigned to this component. Similarly, subsite C10, which includes several oropharyngeal regions, is assigned roughly 50% to the oropharynx-like component, with the remaining mixture distributed across the other two components.

Hypopharyngeal subsites, on the other hand, are fully assigned to Component 2, located at the top vertex of the triangle. Meanwhile, the gum subsite (C03), with predominant LNL I involvement, is entirely assigned to Component 1, situated at the bottom left.
As subsites anatomically approach the oropharynx, their mixture coefficients for the oropharynx-like component increase. This is evident in the subsites C02 (tongue) and C05 (palate), which display a higher proportion of oropharyngeal influence in their mixture. These results conform well with the involvement patterns observed in the data.

::: {layout="[75,30]" layout-valign="bottom"}

![Assignment of each subsite to each of the three components. The closer a subsite is to a vertex, the more it is assigned to the corresponding component, with component 0 on the bottom right, 1 on the bottom left and 2 on the top. The size of the marker (area) corresponds to the number of patients in each subsite.](figures/mixture_components_3_simplex_t_stages_new.png){#fig-3_simplex}

![Matrix representation of component assignment. Each row of the matrix corresponds to each ICD code. The collums represent the three different components](figures/mixture_components_3_t_stages_new.png){#fig-3-matrix}
:::

# Four component Mixture Model {#sec-4comp}

We can extend the mixture model to include the larynx. The larynx patients are more finely divided into ICD codes C32.0, C32.1 and C32.2 as there is a notable difference between these ICD codes in @fig-involvement.

Simlarly to the three component model, we can analyze the convergence over the iterations of the EM-algorithm. In @fig-convergence4 we can see that in this more complex model, the likelihood space becomes more complex as at around 200 iterations, the negative log-likelihood starts to increase faster again.

![The y-axis on the left shows the negative likelihood convergence depicted in the blue line. The y-axis on the right shows the sum of absulte difference between all model parameters.](figures/convergence_4_components_4_loc.png){#fig-convergence4}

The component assignment is shown in @fig-4-matrix. Similarly to the 3-component model the different tumor locations are assigned to a one of the components....


Here i probably should permute the components such that we have the same ordering as in the 3-component model.

![Matrix representation of component assignment. Each row of the matrix corresponds to each ICD code. The collums represent the three different components](figures/mixture_components_4_t_staging_add_larynx.png){#fig-4-matrix}

add some analysis (level specific predictions and also comparison to single tumor location models.)